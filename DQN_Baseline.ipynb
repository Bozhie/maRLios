{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "zsh:1: command not found: apt-get\n",
      "The operation couldn’t be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "Requirement already satisfied: opencv-python in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: gym-super-mario-bros in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (7.4.0)\n",
      "Requirement already satisfied: nes-py>=8.1.4 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from gym-super-mario-bros) (8.2.1)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.23.5)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.21)\n",
      "Requirement already satisfied: gym>=0.17.2 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.25.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "#only run once\n",
    "#!pip install nes-py==0.2.6\n",
    "!apt-get update\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y\n",
    "!apt install -y libgl1-mesa-glx\n",
    "!pip install opencv-python\n",
    "!pip install gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lib.gym_env import *\n",
    "from lib.model import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_action(action, action_space):\n",
    "    # Given a scalar action, return a one-hot encoded action\n",
    "    \n",
    "    return [0 for _ in range(action)] + [1] + [0 for _ in range(action + 1, action_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, ep=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"Episode: %d %s\" % (ep, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env):\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    return JoypadSpace(env, RIGHT_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(training_mode, pretrained):\n",
    "   \n",
    "    env = gym.make('SuperMarioBros-1-1-v0')\n",
    "    #env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "    \n",
    "    #env = make_env(env)  # Wraps the environment so that frames are grayscale \n",
    "    #env = SuperMarioBrosEnv()\n",
    "    env = make_env(env)\n",
    "    observation_space = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQNAgent(state_space=observation_space,\n",
    "                     action_space=action_space,\n",
    "                     max_memory_size=30000,\n",
    "                     batch_size=32,\n",
    "                     gamma=0.90,\n",
    "                     lr=0.00025,\n",
    "                     dropout=0.,\n",
    "                     exploration_max=1.0,\n",
    "                     exploration_min=0.02,\n",
    "                     exploration_decay=0.99,\n",
    "                     double_dq=True,\n",
    "                     pretrained=pretrained)\n",
    "    \n",
    "    num_episodes = 10\n",
    "    env.reset()\n",
    "    total_rewards = []\n",
    "    \n",
    "    for ep_num in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        state = torch.Tensor([state])\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while True:\n",
    "            if not training_mode:\n",
    "                show_state(env, ep_num)\n",
    "            action = agent.act(state)\n",
    "            steps += 1\n",
    "            \n",
    "            state_next, reward, terminal, info = env.step(int(action[0]))\n",
    "            total_reward += reward\n",
    "            state_next = torch.Tensor([state_next])\n",
    "            reward = torch.tensor([reward]).unsqueeze(0)\n",
    "            \n",
    "            terminal = torch.tensor([int(terminal)]).unsqueeze(0)\n",
    "            \n",
    "            if training_mode:\n",
    "                agent.remember(state, action, reward, state_next, terminal)\n",
    "                agent.experience_replay()\n",
    "            \n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "        print(\"Total reward after episode {} is {}\".format(ep_num + 1, total_rewards[-1]))\n",
    "        num_episodes += 1      \n",
    "    \n",
    "    if training_mode:\n",
    "        with open(\"ending_position.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.ending_position, f)\n",
    "        with open(\"num_in_queue.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.num_in_queue, f)\n",
    "        with open(\"total_rewards.pkl\", \"wb\") as f:\n",
    "            pickle.dump(total_rewards, f)\n",
    "        if agent.double_dq:\n",
    "            torch.save(agent.local_net.state_dict(), \"dq1.pt\")\n",
    "            torch.save(agent.target_net.state_dict(), \"dq2.pt\")\n",
    "        else:\n",
    "            torch.save(agent.dqn.state_dict(), \"dq.pt\")  \n",
    "        torch.save(agent.STATE_MEM,  \"STATE_MEM.pt\")\n",
    "        torch.save(agent.ACTION_MEM, \"ACTION_MEM.pt\")\n",
    "        torch.save(agent.REWARD_MEM, \"REWARD_MEM.pt\")\n",
    "        torch.save(agent.STATE2_MEM, \"STATE2_MEM.pt\")\n",
    "        torch.save(agent.DONE_MEM,   \"DONE_MEM.pt\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    if num_episodes > 500:\n",
    "        plt.title(\"Episodes trained vs. Average Rewards (per 500 eps)\")\n",
    "        plt.plot([0 for _ in range(500)] + \n",
    "                 np.convolve(total_rewards, np.ones((500,))/500, mode=\"valid\").tolist())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/Users/bozhiepokorny/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      " 10%|████▍                                       | 1/10 [00:00<00:02,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward after episode 1 is 248.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▏                                | 2/10 [14:43<1:09:15, 519.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward after episode 2 is 230.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▉                              | 3/10 [15:39<35:56, 308.06s/it]"
     ]
    }
   ],
   "source": [
    "run(training_mode=True, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlios",
   "language": "python",
   "name": "marlios"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
