{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "from toolkit.train_marlios_lstm import *\n",
    "from toolkit.marlios_lstm import *\n",
    "from toolkit.constants import *\n",
    "from toolkit.train_test_samples import *\n",
    "import warnings\n",
    "import wandb \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(\n",
    "    name='LSTM debug',\n",
    "    training_mode=True, \n",
    "    pretrained=False, # use the pretrained model\n",
    "    ep_per_stat=10, \n",
    "    gamma=0.9,\n",
    "    num_episodes=100,\n",
    "    run_id=None,\n",
    "    lr=0.000005, \n",
    "    lr_decay= 0.99,\n",
    "    exploration_min=0.05,\n",
    "    exploration_max = 1, # setting this to the min for the rerun model\n",
    "    exploration_decay=0.99, \n",
    "    action_space=TRAIN_SET,\n",
    "    n_actions=1,\n",
    "    debug=True,\n",
    "    device='mps',\n",
    "    max_time_per_ep=150, # limit runs to a fewer seconds,\n",
    "    log = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run if you cut the above off early, even then you don't 'have' to but it will do it automatically for you, it's just not as nice to have the output above as well\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp ModelCheckpoints/*1682283822* . resetting this run here\n",
    "\n",
    "total_rewards = load_item('total_rewards-{}.pkl'.format(run_id))\n",
    "plot_rewards(ep_per_stat=100, total_rewards=total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
